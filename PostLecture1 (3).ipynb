{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2883ee",
   "metadata": {},
   "source": [
    "The count statistic provided in the describe() method is the total number of observations in each column.\n",
    "The mean is the average value of the data within the column, and is calculated by adding all the values then dividing by the count.\n",
    "std is the standard deviation and shows approximately how far each value is from the mean, it is calculated by taking the square of each data point subtracted by the mean, then dividing it by the sample size minus 1, afterwards squarerooting the entire equation.\n",
    "min shows the lowest value in the column\n",
    "25% is the value which 25% of the data falls under\n",
    "50%/median is the value which splits the data into 2 halves, one higher one lower.\n",
    "75% is the value which 75% of the data falls below\n",
    "max shows the highest value in the column \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b909e",
   "metadata": {},
   "source": [
    "Using df.dropna() might be preferred over using df.del['col'] when you are trying to remove a specific row from the data, while not disrupting the entire column, it may also be preferred in cases where you are trying to efficiently remove any columns or rows that have missing data, and can even be fine tuned to only remove columns or rows when the entire section is missing, or based on a certain threshold(eg. at least 1 NaN), saving a lot of time in the analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b1635",
   "metadata": {},
   "source": [
    "The df.del['col'] can also be useful in certain scenarios, such as wanting to remove a column that you know wants to be removed, df.del is more direct and simpler to use, and also is useful when you want to target a specific column with missing values but don't want to delete another column with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a1f1c",
   "metadata": {},
   "source": [
    "Using df.del before dropna() may be important in cases where you want to selectively delete a column with a lot of missing values without automatically deleting certain columns with missing values that you do not want deleted, but otherwise would have deleted with dropna(). Then using dropna() you can remove the rows that those missing values inhabit to limit the amount of data lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d365dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876898a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Shape of the DataFrame: (891, 15)\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "After cleaning:\n",
      "Shape of the cleaned DataFrame: (889, 13)\n",
      "   survived  pclass     sex  sibsp  parch     fare embarked  class    who  \\\n",
      "0         0       3    male      1      0   7.2500        S  Third    man   \n",
      "1         1       1  female      1      0  71.2833        C  First  woman   \n",
      "2         1       3  female      0      0   7.9250        S  Third  woman   \n",
      "3         1       1  female      1      0  53.1000        S  First  woman   \n",
      "4         0       3    male      0      0   8.0500        S  Third    man   \n",
      "\n",
      "   adult_male  embark_town alive  alone  \n",
      "0        True  Southampton    no  False  \n",
      "1       False    Cherbourg   yes  False  \n",
      "2       False  Southampton   yes   True  \n",
      "3       False  Southampton   yes  False  \n",
      "4        True  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Show the number of rows and columns before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"Shape of the DataFrame: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# Remove rows with missing data\n",
    "del df['age']\n",
    "del df['deck']\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Show the number of rows and columns after cleaning\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Shape of the cleaned DataFrame: {df_cleaned.shape}\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beea978",
   "metadata": {},
   "source": [
    "To remove all missing data efficiently I analyzed the columns that are missing the most data points and then used del df[] on the two columns with a major shortage in data, those being the age and deck columns. then, using dropna(), I dropped the rows that were missing a few data points, the reasoning behind this is to reduce the amount of data loss since there is only 2 data points missing in embarked and embarked_town columns, so I did not want to delete the entire column of 891 data points over 2 missing variables, so I instead deleted the rows that those points inhabited with dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c315e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count       mean        std  min      25%   50%   75%       max\n",
      "survived                                                                 \n",
      "0         549.0  22.117887  31.388207  0.0   7.8542  10.5  26.0  263.0000\n",
      "1         342.0  48.395408  66.596998  0.0  12.4750  26.0  57.0  512.3292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'pclass' and describe the 'age' column\n",
    "summary = df.groupby('survived')['fare'].describe()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5314f7a",
   "metadata": {},
   "source": [
    "The df.groupby(\"col1\")[\"col2\"].describe() sorts and divides the data into groups which is based off the unique values in 'col1'. the [\"col2\"] chooses the col2 group from each group, and focuses the analysis on the data within that column. The describe() then carries out the analysis with the col2 from each group, displaying the count, mean, std, min, 25/50/75%, and finally the max of each group within col1. \n",
    "\n",
    "The example shown above shows the use of this method by sectioning the data into survived, or did not survive, and finally analyses the fare paid by each individual within each group. We can see that the mean average cost of the fare is much higher with those that survived than those that did not, implying some sort of special treatment over safety and evacuation procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad1dab",
   "metadata": {},
   "source": [
    "The count value shown by describe() shows the total number of variables within each observation, where as the one shown by groupby.('col1')[\"col2\"].describe() shows the count of data within each unique variable within a column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a07b1",
   "metadata": {},
   "source": [
    "ChatGPT helps fix errors much more efficiently and quickly when compared to a google search as it accurately analyses the problem and provides a patch of code that can be pasted in to quickly fix the problem. With most of these problems, I find that there is no point in searching on google to fix the issue as it takes alot more effort to find and locate the place of issue and to spend time thinking about the issue and to fix it, while using ChatGPT makes it much more effortless and efficient. I find that using google to search up the issue takes marginally more time compared to asking ChatGPT as you first have to type in what you think the error potentially is, and then do extra research to learn how to fix it, with it sometimes even giving you unhelpful links and information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1313d2f",
   "metadata": {},
   "source": [
    "Here's a summary of the conversation:\n",
    "\n",
    "Initial Request: You wanted to understand a specific operation in Python using the Titanic datasetâ€”df.groupby(\"col1\")[\"col2\"].describe(). I explained that this code groups the data by col1 and then provides descriptive statistics for col2 within each group.\n",
    "\n",
    "Example Using Titanic Dataset: You asked for an example using the Titanic dataset. I provided code that grouped the Titanic data by passenger class (pclass) and described the age column.\n",
    "\n",
    "Fixing Errors:\n",
    "\n",
    "NameError: You encountered a NameError because you forgot to import pandas. I suggested adding import pandas as pd.\n",
    "HTTPError: A 404 error was triggered because of a typo in the URL. I provided the correct URL.\n",
    "NameError for DF: You accidentally used DF (uppercase) instead of df (lowercase), which caused an error. I pointed out that Python is case-sensitive and suggested using df.\n",
    "SyntaxError: A missing closing parenthesis was identified and corrected.\n",
    "AttributeError: You had a typo in the method name .describel(), which I corrected to .describe().\n",
    "KeyError: You used 'Survived' (uppercase), but the correct column name is 'survived' (lowercase). I pointed out the case-sensitivity and provided a fix.\n",
    "NameError for 'survived': You forgot to put quotes around the column name 'survived'. I clarified that column names should be treated as strings and need quotes.\n",
    "Finally, I provided the corrected code for each step, ensuring proper execution.\n",
    "https://chatgpt.com/share/ab3d4f0f-9c18-4634-82ce-cc6c5f0bf2b0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
